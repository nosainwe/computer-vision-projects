# ğŸ›°ï¸ Aerial Military Asset Detection (YOLO11n)

Detect objects such as **vehicles, personnel, and equipment** in aerial / surveillance images using a **fineâ€‘tuned YOLO11n** model (Ultralytics).

> âš ï¸ **Responsible use**
> This repository is for **computerâ€‘vision learning and defensive/security research**. Do not use it to support harm, targeting, or wrongdoing.

---

## ğŸ“¦ Dataset

Your original dataset link (`amanbarthwal/amad-5-aerial-military-asset-detection`) currently returns **404 on Kaggle**, so itâ€™s not reliable to share in a public README.

âœ… Use this active Kaggle dataset instead (YOLO format):
- **Military Assets Dataset (12 Classes â€“ YOLO format)**:  
  https://www.kaggle.com/datasets/rawsi18/military-assets-dataset-12-classes-yolo8-format

### Expected folder layout

After downloading and extracting, place the dataset here:

```text
data/military-assets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ dataset.yaml
```

Example `dataset.yaml` (edit paths/classes to match your dataset):

```yaml
path: data/military-assets
train: train/images
val: val/images
test: test/images

names:
  0: soldier
  1: vehicle
  2: artillery
  3: helicopter
  4: tank
  5: ship
  6: aircraft
  7: drone
  8: weapon
  9: radar
  10: missile
  11: other
```

> Note: class names vary by dataset version. Confirm yours by checking the provided `dataset.yaml`.

---

## âš™ï¸ Setup

### 1) Create a virtual environment (recommended)

```bash
python -m venv .venv
# Windows:
# .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```

### 2) Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ‹ï¸ Training

Run training:

```bash
python main.py --mode train
```

Typical training defaults (adjust in `main.py` if needed):
- Pretrained **YOLO11n** weights as a starting point
- ~20 epochs (good baseline while learning)
- 1024Ã—1024 image size (helps with small objects in aerial views)

ğŸ“ Outputs are saved under:

```text
runs/detect/train/
â””â”€â”€ weights/
    â”œâ”€â”€ best.pt
    â””â”€â”€ last.pt
```

---

## âœ… Evaluation

Evaluate on the test split:

```bash
python main.py --mode evaluate
```

This should:
- print mAP metrics (e.g., mAP@0.5, mAP@0.5:0.95)
- save prediction visualisations to a `runs/` folder

---

## ğŸ” Inference

Run inference on a single image:

```bash
python main.py --mode predict --source path/to/image.jpg
```

Run inference on a folder:

```bash
python main.py --mode predict --source path/to/images/
```

Results will be saved to:

```text
runs/detect/predict/
```

---

## ğŸ“Š Results (example)

After ~20 epochs, a typical baseline can reach strong validation performance depending on class balance and image quality.

> Replace this with your real numbers after you run training:
- **mAP@0.5 (val):** `__`
- **mAP@0.5:0.95 (val):** `__`

---

## ğŸ§° Tips to improve performance

- âœ… Use **class rebalancing** if a few classes dominate
- âœ… Try `yolo11s` or `yolo11m` if your GPU can handle it
- âœ… Add augmentation for aerial views: rotation, scale, blur, haze
- âœ… Check label quality â€” noisy labels destroy mAP faster than anything

---

## ğŸ™ Acknowledgements

- **Ultralytics YOLO** (training/inference framework): https://github.com/ultralytics/ultralytics  
- Dataset source (Kaggle): https://www.kaggle.com/datasets/rawsi18/military-assets-dataset-12-classes-yolo8-format
