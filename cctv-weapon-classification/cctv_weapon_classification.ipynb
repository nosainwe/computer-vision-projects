{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCTV Weapon Detection using Transfer Learning\n",
    "\n",
    "**Binary classifier** – predicts whether a surveillance image contains a weapon (gun/knife).\n",
    "\n",
    "Dataset: [CCTV Weapon Detection](https://www.kaggle.com/datasets/simuletic/cctv-weapon-dataset) (Simuletic)\n",
    "\n",
    "Approach: Transfer learning with MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set paths\n",
    "\n",
    "Make sure the dataset is downloaded and placed in `data/cctv-weapon-dataset/`.\n",
    "\n",
    "Folder structure:\n",
    "```\n",
    "data/\n",
    "└── cctv-weapon-dataset/\n",
    "    ├── images/          # all .jpg/.png files\n",
    "    └── labels/          # corresponding .txt files (YOLO format)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"data/cctv-weapon-dataset\"\n",
    "IMAGE_DIR = os.path.join(BASE_DIR, \"images\")\n",
    "LABEL_DIR = os.path.join(BASE_DIR, \"labels\")\n",
    "\n",
    "# Verify folders exist\n",
    "assert os.path.exists(IMAGE_DIR), f\"Image directory not found: {IMAGE_DIR}\"\n",
    "assert os.path.exists(LABEL_DIR), f\"Label directory not found: {LABEL_DIR}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse YOLO labels to create binary classes\n",
    "\n",
    "YOLO format: `class_id x_center y_center width height` (normalized).\n",
    "\n",
    "Class mapping: 0 = `person`, 1 = `weapon`.\n",
    "\n",
    "For each image, we check its corresponding `.txt` label file. If any annotation has `class_id == 1`, the image contains a weapon. Otherwise, it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths_and_labels(img_dir, lbl_dir):\n",
    "    \"\"\"Return two lists: full image paths and binary labels (1=weapon, 0=no weapon).\"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    # Get all image files (common extensions)\n",
    "    img_extensions = ('.jpg', '.jpeg', '.png')\n",
    "    img_files = [f for f in os.listdir(img_dir) if f.lower().endswith(img_extensions)]\n",
    "    \n",
    "    for img_file in img_files:\n",
    "        # Corresponding label file (replace extension with .txt)\n",
    "        label_file = os.path.splitext(img_file)[0] + '.txt'\n",
    "        label_path = os.path.join(lbl_dir, label_file)\n",
    "        \n",
    "        weapon_present = 0  # default: no weapon\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 1:\n",
    "                    class_id = int(parts[0])\n",
    "                    if class_id == 1:  # weapon class\n",
    "                        weapon_present = 1\n",
    "                        break  # no need to check further\n",
    "        else:\n",
    "            print(f\"Warning: label file not found for {img_file}\")\n",
    "        \n",
    "        image_paths.append(os.path.join(img_dir, img_file))\n",
    "        labels.append(weapon_present)\n",
    "    \n",
    "    return image_paths, labels\n",
    "\n",
    "img_paths, labels = get_image_paths_and_labels(IMAGE_DIR, LABEL_DIR)\n",
    "\n",
    "print(f\"Total images: {len(img_paths)}\")\n",
    "print(f\"Class distribution: weapon={sum(labels)}, no weapon={len(labels)-sum(labels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train / validation / test split\n",
    "\n",
    "We'll use 70% train, 15% validation, 15% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: train vs temp (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    img_paths, labels, test_size=0.3, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Second split: val vs test (50% of temp each)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} images\")\n",
    "print(f\"Validation: {len(X_val)} images\")\n",
    "print(f\"Test: {len(X_test)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data generators with augmentation\n",
    "\n",
    "We'll use `ImageDataGenerator` to load images on‑the‑fly and apply augmentation only to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)  # MobileNetV2 expected input size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Function to create a generator from lists of paths and labels\n",
    "def create_generator(paths, labels, batch_size, augment=False):\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        rotation_range=20 if augment else 0,\n",
    "        width_shift_range=0.2 if augment else 0,\n",
    "        height_shift_range=0.2 if augment else 0,\n",
    "        horizontal_flip=True if augment else False,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    \n",
    "    # Create a DataFrame for flow_from_dataframe\n",
    "    df = pd.DataFrame({'filename': paths, 'class': labels})\n",
    "    generator = datagen.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col='filename',\n",
    "        y_col='class',\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='raw',          # raw because labels are already 0/1\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "train_gen = create_generator(X_train, y_train, BATCH_SIZE, augment=True)\n",
    "val_gen   = create_generator(X_val,   y_val,   BATCH_SIZE, augment=False)\n",
    "test_gen  = create_generator(X_test,  y_test,  BATCH_SIZE, augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build the model (Transfer Learning with MobileNetV2)\n",
    "\n",
    "- Load MobileNetV2 without the top classification layer.\n",
    "- Freeze the base model (use it as feature extractor).\n",
    "- Add a global average pooling layer, a dense layer, and a final sigmoid output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False  # freeze\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the model\n",
    "\n",
    "We'll use early stopping to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=5, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset test generator to avoid shuffling issues\n",
    "test_gen.reset()\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Predictions and true labels\n",
    "y_pred_prob = model.predict(test_gen)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "# True labels from test_gen (they are in the same order after reset)\n",
    "y_true = test_gen.labels[:len(y_pred)]  # ensure same length\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['No weapon', 'Weapon']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No weapon', 'Weapon'],\n",
    "            yticklabels=['No weapon', 'Weapon'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,4))\n",
    "\n",
    "ax1.plot(history.history['loss'], label='train')\n",
    "ax1.plot(history.history['val_loss'], label='validation')\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(history.history['accuracy'], label='train')\n",
    "ax2.plot(history.history['val_accuracy'], label='validation')\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Show sample predictions\n",
    "\n",
    "Visualise a few test images with true and predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(model, paths, true_labels, num_samples=8):\n",
    "    \"\"\"Display images with true and predicted labels.\"\"\"\n",
    "    indices = random.sample(range(len(paths)), num_samples)\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for i, idx in enumerate(indices):\n",
    "        img_path = paths[idx]\n",
    "        true_label = true_labels[idx]\n",
    "        \n",
    "        # Load and preprocess image for prediction\n",
    "        img = image.load_img(img_path, target_size=IMG_SIZE)\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array = preprocess_input(img_array)\n",
    "        \n",
    "        pred_prob = model.predict(img_array, verbose=0)[0][0]\n",
    "        pred_label = 1 if pred_prob > 0.5 else 0\n",
    "        \n",
    "        # Load original image for display\n",
    "        orig_img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.subplot(2, 4, i+1)\n",
    "        plt.imshow(orig_img)\n",
    "        color = 'green' if pred_label == true_label else 'red'\n",
    "        title = f\"True: {'Weapon' if true_label else 'No weapon'}\\nPred: {'Weapon' if pred_label else 'No weapon'}\"\n",
    "        plt.title(title, color=color)\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_predictions(model, X_test, y_test, num_samples=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save the model (optional)\n",
    "\n",
    "You can save the trained model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save(\"cctv_weapon_classifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Notebook complete.** Thank you for following along!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
